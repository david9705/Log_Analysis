{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 5487\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = def count_event(root, event_collect):\n",
    "\n",
    "def count_event(path, event_collect):\n",
    "    #print(path)\n",
    "    dataset = pd.read_json(path, lines=True)\n",
    "    event_count = dict()\n",
    "    for i in range(0, len(dataset)):\n",
    "        event_id = dataset['winlog'][i]['event_id']\n",
    "        if event_id not in event_count:\n",
    "            event_count[event_id] = 1\n",
    "        else:\n",
    "            event_count[event_id] += 1\n",
    "            \n",
    "    event_collect.update(event_count)\n",
    "    return event_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_event_test(path, event_collect):\n",
    "    #print(path)\n",
    "    dataset = pd.read_json(path, lines=True)\n",
    "    event_count = dict()\n",
    "    for i in range(0, len(dataset)):\n",
    "        event_id = dataset['winlog'][i]['event_id']\n",
    "        if event_id not in event_count and event_id in event_collect:\n",
    "            event_count[event_id] = 1\n",
    "        elif event_id in event_count and event_id in event_collect:\n",
    "            event_count[event_id] += 1\n",
    "            \n",
    "    event_collect.update(event_count)\n",
    "    return event_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_records(path, event_collect, test_data = False):\n",
    "    data = list()\n",
    "    for user in sorted(os.listdir(path)):\n",
    "        event_count = Counter()\n",
    "        atk = os.path.join(path, user, 'winlogbeat.json')\n",
    "        \n",
    "        if not test_data:\n",
    "            event_count.update(count_event(atk, event_collect))\n",
    "        else:\n",
    "            event_count.update(count_event_test(atk, event_collect))\n",
    "        \n",
    "        \n",
    "        data.append(event_count.most_common())\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, event_collect, print_info=True):\n",
    "    normalized_data = list()\n",
    "    for i, user_record in enumerate(data):\n",
    "        event_set = dict()\n",
    "        total_events = 0\n",
    "        for event, freq in user_record:\n",
    "            event_set[event] = freq\n",
    "            total_events += freq\n",
    "            \n",
    "        if print_info:\n",
    "            print(f\"User {i + 1}'s event distribution: \\n{[(event, event_set[event]) for event in sorted(event_set)]}\\n\")\n",
    "        \n",
    "        for event in event_set:\n",
    "            if event not in event_set:\n",
    "                event_set[event] = 1\n",
    "                total_events += 1\n",
    "        \n",
    "        normalized_events = list()\n",
    "        for event in sorted(event_collect):\n",
    "            if event not in event_set:\n",
    "                normalized_events.append(1 / total_events)\n",
    "            else:\n",
    "                normalized_events.append(event_set[event] / total_events)\n",
    "        \n",
    "        normalized_data.append(normalized_events)\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_path, event_collect):\n",
    "    with torch.no_grad():\n",
    "        test_data = read_records(test_path,  event_collect,True)\n",
    "        #here here 原本的training data只有35種 可是testing有37種\n",
    "        test_data = torch.FloatTensor(normalize(test_data, event_collect, False)).to(device)\n",
    "        #print(test_data.shape)\n",
    "        predict = model.forward(test_data)\n",
    "#         print(predict, '\\n')\n",
    "        \n",
    "    return torch.argmax(predict, dim=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnect(nn.Module):\n",
    "    def __init__(self, num_events):\n",
    "        super(FullyConnect, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_events, 100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100, 5)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/NS_project2/Logs/Train'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mode = str(sys.argv[2])\n",
    "data_root = os.path.join(os.getcwd(), 'Logs')\n",
    "train_path = os.path.join(data_root, 'Train')\n",
    "test_path = os.path.join(str(sys.argv[1]))\n",
    "event_collect = set()\n",
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1's event distribution: \n",
      "[(4624, 11), (4656, 4569), (4658, 2167), (4663, 919), (4672, 11), (4688, 79), (4689, 78), (4690, 1061), (4702, 1), (4703, 22), (4798, 1), (4799, 4), (5379, 26), (7040, 4), (10016, 1)]\n",
      "\n",
      "User 2's event distribution: \n",
      "[(4624, 4), (4656, 5859), (4658, 4533), (4663, 2135), (4672, 4), (4688, 58), (4689, 56), (4690, 2244), (4703, 15)]\n",
      "\n",
      "User 3's event distribution: \n",
      "[(26, 1), (4624, 4), (4656, 943), (4658, 1855), (4660, 2), (4663, 731), (4670, 8), (4672, 4), (4688, 79), (4689, 75), (4690, 919), (4698, 1), (4703, 28), (4798, 5), (5156, 357), (5158, 167), (7045, 1)]\n",
      "\n",
      "User 4's event distribution: \n",
      "[(15, 2), (4624, 19), (4625, 1), (4634, 8), (4648, 2), (4656, 3571), (4658, 7193), (4660, 4), (4663, 2632), (4672, 21), (4688, 106), (4689, 101), (4690, 3625), (4702, 1), (4703, 26), (4719, 6), (4798, 25), (5058, 1), (5061, 1), (5156, 790), (5158, 146), (5379, 1), (5381, 2), (5382, 5), (6416, 17), (10016, 1), (16384, 1), (16394, 1)]\n",
      "\n",
      "User 5's event distribution: \n",
      "[(1001, 1), (4624, 8), (4656, 4958), (4658, 2640), (4663, 1114), (4672, 8), (4688, 74), (4689, 81), (4690, 1299), (4703, 22), (4799, 2), (5379, 13), (5382, 3)]\n",
      "\n",
      "torch.Size([5, 35])\n"
     ]
    }
   ],
   "source": [
    "train_data = read_records(train_path, event_collect)\n",
    "train_data = torch.FloatTensor(normalize(train_data, event_collect)).to(device)\n",
    "print(train_data.shape)\n",
    "label = torch.LongTensor([0, 1, 2, 3, 4]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullyConnect(train_data.shape[1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4104757308959961 [1, 2, 3, 4, 5]\n",
      "0.07392624765634537 [1, 2, 3, 4, 5]\n",
      "0.024139681831002235 [1, 2, 3, 4, 5]\n",
      "0.01182499434798956 [1, 2, 3, 4, 5]\n",
      "0.0070427716709673405 [1, 2, 3, 4, 5]\n",
      "0.0046871500089764595 [1, 2, 3, 4, 5]\n",
      "0.003348772879689932 [1, 2, 3, 4, 5]\n",
      "0.0025125571992248297 [1, 2, 3, 4, 5]\n",
      "0.0019541876390576363 [1, 2, 3, 4, 5]\n",
      "0.0015619860496371984 [1, 2, 3, 4, 5]\n",
      "0.001275727991014719 [1, 2, 3, 4, 5]\n",
      "0.0010602741967886686 [1, 2, 3, 4, 5]\n",
      "0.0008937337552197278 [1, 2, 3, 4, 5]\n",
      "0.0007624734425917268 [1, 2, 3, 4, 5]\n",
      "0.0006570810219272971 [1, 2, 3, 4, 5]\n",
      "0.000571254757232964 [1, 2, 3, 4, 5]\n",
      "0.0005003082333132625 [1, 2, 3, 4, 5]\n",
      "0.0004411012923810631 [1, 2, 3, 4, 5]\n",
      "0.0003911109524779022 [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "test_path = '/root/NS_project2/Logs/Example_Test'\n",
    "\n",
    "for epoch in range(1, 2000):\n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predict = model(train_data)\n",
    "        loss = criterion(predict, label)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            model.eval()\n",
    "            predict = test(model, test_path, event_collect).cpu().tolist()\n",
    "            print(total_loss, predict)\n",
    "\n",
    "            model.train()\n",
    "torch.save(model.state_dict(), 'weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestCase 1: Attack1\n",
      "TestCase 2: Attack2\n",
      "TestCase 3: Attack3\n",
      "TestCase 4: Attack4\n",
      "TestCase 5: Attack5\n"
     ]
    }
   ],
   "source": [
    "predict = test(model, test_path, event_collect).cpu().tolist()\n",
    "for i, label in enumerate(predict):\n",
    "    print(f\"TestCase {i + 1}: Attack{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
